{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------Question 1---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_heading = soup.find('h1',class_ = \"firstHeading\")\n",
    "first_heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Main Page'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fh = first_heading.text\n",
    "fh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfl-h2\"><span id=\"From_today.27s_featured_list\"></span><span class=\"mw-headline\" id=\"From_today's_featured_list\">From today's featured list</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_heading = soup.find_all('h2', class_ = 'mp-h2')\n",
    "second_heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From today's featured article\",\n",
       " 'Did you know',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"From today's featured list\",\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh = []\n",
    "for i in second_heading:\n",
    "    sh.append(i.text.replace('\\xa0...',''))\n",
    "    \n",
    "sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"wikipedia-languages-count\" role=\"heading\">1,000,000+ articles</div>,\n",
       " <div class=\"wikipedia-languages-count\" role=\"heading\">250,000+ articles</div>,\n",
       " <div class=\"wikipedia-languages-count\" role=\"heading\">50,000+ articles</div>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = soup.find_all('div', role = 'heading')\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,000,000+ articles', '250,000+ articles', '50,000+ articles']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = []\n",
    "for i in header:\n",
    "    headers.append(i.text)\n",
    "    \n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh.append(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh.append(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From today's featured article\",\n",
       " 'Did you know',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"From today's featured list\",\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages',\n",
       " 'Main Page',\n",
       " ['1,000,000+ articles', '250,000+ articles', '50,000+ articles']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_tag_list = sh\n",
    "header_tag_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------- Question 2---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/chart/top/?ref_=nv_mv_250')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title = soup.find_all('td', class_ = 'titleColumn')\n",
    "# movie_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Shawshank Redemption',\n",
       " 'The Godfather',\n",
       " 'The Godfather: Part II',\n",
       " 'The Dark Knight',\n",
       " '12 Angry Men',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'Pulp Fiction',\n",
       " 'Il buono, il brutto, il cattivo',\n",
       " ' The Lord of the Rings: The Fellowship of the Ring',\n",
       " ' Fight Club',\n",
       " ' Forrest Gump',\n",
       " ' Inception',\n",
       " ' The Lord of the Rings: The Two Towers',\n",
       " ' Star Wars: Episode V - The Empire Strikes Back',\n",
       " ' The Matrix',\n",
       " ' Goodfellas',\n",
       " \" One Flew Over the Cuckoo's Nest\",\n",
       " ' Shichinin no samurai',\n",
       " ' Se7en',\n",
       " ' The Silence of the Lambs',\n",
       " ' Cidade de Deus',\n",
       " \" It's a Wonderful Life\",\n",
       " ' La vita è bella',\n",
       " ' Star Wars',\n",
       " ' Saving Private Ryan',\n",
       " ' Sen to Chihiro no kamikakushi',\n",
       " ' The Green Mile',\n",
       " ' Interstellar',\n",
       " ' Gisaengchung',\n",
       " ' Léon',\n",
       " ' Seppuku',\n",
       " ' The Usual Suspects',\n",
       " ' The Pianist',\n",
       " ' Back to the Future',\n",
       " ' Terminator 2: Judgment Day',\n",
       " ' Modern Times',\n",
       " ' Psycho',\n",
       " ' The Lion King',\n",
       " ' American History X',\n",
       " ' City Lights',\n",
       " ' Gladiator',\n",
       " ' Whiplash',\n",
       " ' The Departed',\n",
       " ' Hotaru no haka',\n",
       " ' The Intouchables',\n",
       " ' The Prestige',\n",
       " ' Casablanca',\n",
       " ' Once Upon a Time in the West',\n",
       " ' Rear Window',\n",
       " ' Nuovo Cinema Paradiso',\n",
       " ' Alien',\n",
       " ' Apocalypse Now',\n",
       " ' Memento',\n",
       " ' Raiders of the Lost Ark',\n",
       " ' The Great Dictator',\n",
       " ' The Lives of Others',\n",
       " ' Django Unchained',\n",
       " ' Paths of Glory',\n",
       " ' Sunset Blvd.',\n",
       " ' WALL·E',\n",
       " ' The Shining',\n",
       " ' Witness for the Prosecution',\n",
       " ' Avengers: Infinity War',\n",
       " ' Joker',\n",
       " ' Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb',\n",
       " ' Spider-Man: Into the Spider-Verse',\n",
       " ' Mononoke-hime',\n",
       " ' Oldeuboi',\n",
       " ' Hamilton',\n",
       " ' Pather Panchali',\n",
       " ' Once Upon a Time in America',\n",
       " ' Kimi no na wa.',\n",
       " ' The Dark Knight Rises',\n",
       " ' Aliens',\n",
       " ' Coco',\n",
       " ' Das Boot',\n",
       " ' Capharnaüm',\n",
       " ' Tengoku to jigoku',\n",
       " ' Avengers: Endgame',\n",
       " ' American Beauty',\n",
       " ' Toy Story',\n",
       " ' Braveheart',\n",
       " ' Amadeus',\n",
       " ' 3 Idiots',\n",
       " ' Inglourious Basterds',\n",
       " ' Good Will Hunting',\n",
       " ' Star Wars: Episode VI - Return of the Jedi',\n",
       " ' 2001: A Space Odyssey',\n",
       " ' Reservoir Dogs',\n",
       " ' M - Eine Stadt sucht einen Mörder',\n",
       " ' Taare Zameen Par',\n",
       " ' Citizen Kane',\n",
       " ' Vertigo',\n",
       " ' Requiem for a Dream',\n",
       " ' Jagten',\n",
       " \" Singin' in the Rain\",\n",
       " ' North by Northwest',\n",
       " ' Eternal Sunshine of the Spotless Mind',\n",
       " '  Idi i smotri']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_list = []\n",
    "for i in movie_title:\n",
    "    movie_title_list.append(i.text.replace('\\n','').strip())\n",
    "    \n",
    "mtl1 = movie_title_list[:100]\n",
    "\n",
    "mtl2= []\n",
    "for i in mtl1:\n",
    "    mtl2.append(i.replace(i[-6:],''))\n",
    "mtl2\n",
    "mtl3 = []\n",
    "for i in mtl2:\n",
    "    mtl3.append(i.replace(i[0:8],''))\n",
    "mtl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1994',\n",
       " '1972',\n",
       " '1974',\n",
       " '2008',\n",
       " '1957',\n",
       " '1993',\n",
       " '2003',\n",
       " '1994',\n",
       " '1966',\n",
       " '2001',\n",
       " '1999',\n",
       " '1994',\n",
       " '2010',\n",
       " '2002',\n",
       " '1980',\n",
       " '1999',\n",
       " '1990',\n",
       " '1975',\n",
       " '1954',\n",
       " '1995',\n",
       " '1991',\n",
       " '2002',\n",
       " '1946',\n",
       " '1997',\n",
       " '1977',\n",
       " '1998',\n",
       " '2001',\n",
       " '1999',\n",
       " '2014',\n",
       " '2019',\n",
       " '1994',\n",
       " '1962',\n",
       " '1995',\n",
       " '2002',\n",
       " '1985',\n",
       " '1991',\n",
       " '1936',\n",
       " '1960',\n",
       " '1994',\n",
       " '1998',\n",
       " '1931',\n",
       " '2000',\n",
       " '2014',\n",
       " '2006',\n",
       " '1988',\n",
       " '2011',\n",
       " '2006',\n",
       " '1942',\n",
       " '1968',\n",
       " '1954',\n",
       " '1988',\n",
       " '1979',\n",
       " '1979',\n",
       " '2000',\n",
       " '1981',\n",
       " '1940',\n",
       " '2006',\n",
       " '2012',\n",
       " '1957',\n",
       " '1950',\n",
       " '2008',\n",
       " '1980',\n",
       " '1957',\n",
       " '2018',\n",
       " '2019',\n",
       " '1964',\n",
       " '2018',\n",
       " '1997',\n",
       " '2003',\n",
       " '2020',\n",
       " '1955',\n",
       " '1984',\n",
       " '2016',\n",
       " '2012',\n",
       " '1986',\n",
       " '2017',\n",
       " '1981',\n",
       " '2018',\n",
       " '1963',\n",
       " '2019',\n",
       " '1999',\n",
       " '1995',\n",
       " '1995',\n",
       " '1984',\n",
       " '2009',\n",
       " '2009',\n",
       " '1997',\n",
       " '1983',\n",
       " '1968',\n",
       " '1992',\n",
       " '1931',\n",
       " '2007',\n",
       " '1941',\n",
       " '1958',\n",
       " '2000',\n",
       " '2012',\n",
       " '1952',\n",
       " '1959',\n",
       " '2004',\n",
       " '1985']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_list = []\n",
    "for i in mtl1:\n",
    "    year_list.append(i[-5:-1])\n",
    "    \n",
    "yl=year_list\n",
    "yl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating = soup.find_all('td', class_ = \"ratingColumn imdbRating\")\n",
    "# movie_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '9.1',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_rating_list = []\n",
    "for i in movie_rating:\n",
    "    movie_rating_list.append(i.text.replace('\\n',''))\n",
    "    \n",
    "mrl = movie_rating_list [ :100]\n",
    "mrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(mtl3),len(yl),len(mrl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "top_100_movies = pd.DataFrame({})\n",
    "top_100_movies['Name'] = mtl3\n",
    "top_100_movies['IMDB Rating'] = mrl\n",
    "top_100_movies['Year of Release'] = yl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jagten</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Idi i smotri</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name IMDB Rating Year of Release\n",
       "0                 The Shawshank Redemption         9.2            1994\n",
       "1                            The Godfather         9.1            1972\n",
       "2                   The Godfather: Part II         9.0            1974\n",
       "3                          The Dark Knight         9.0            2008\n",
       "4                             12 Angry Men         8.9            1957\n",
       "..                                     ...         ...             ...\n",
       "95                                  Jagten         8.3            2012\n",
       "96                     Singin' in the Rain         8.3            1952\n",
       "97                      North by Northwest         8.3            1959\n",
       "98   Eternal Sunshine of the Spotless Mind         8.3            2004\n",
       "99                            Idi i smotri         8.3            1985\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------QUESTION 3------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup.prettify()\n",
    "name = soup.find_all('td', class_='titleColumn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pather Panchali',\n",
       " 'Nayakan',\n",
       " 'Anbe Sivam',\n",
       " 'Pariyerum Perumal',\n",
       " 'Golmaal',\n",
       " 'Apur Sansar',\n",
       " 'C/o Kancharapalem',\n",
       " 'Drishyam 2',\n",
       " 'Kireedam',\n",
       " ' Manichitrathazhu',\n",
       " ' Natsamrat',\n",
       " ' 96',\n",
       " ' Black Friday',\n",
       " ' Thevar Magan',\n",
       " ' Kumbalangi Nights',\n",
       " ' 3 Idiots',\n",
       " ' Visaaranai',\n",
       " ' Taare Zameen Par',\n",
       " ' Ratsasan',\n",
       " ' Jersey',\n",
       " ' Thalapathi',\n",
       " ' Soorarai Pottru',\n",
       " ' Dangal',\n",
       " ' Asuran',\n",
       " ' Devasuram',\n",
       " ' Aparajito',\n",
       " ' Kaithi',\n",
       " ' Jaane Bhi Do Yaaro',\n",
       " ' Pyaasa',\n",
       " ' Guide',\n",
       " ' Peranbu',\n",
       " ' Vada Chennai',\n",
       " ' Thani Oruvan',\n",
       " ' Kannathil Muthamittal',\n",
       " ' Chupke Chupke',\n",
       " ' Iruvar',\n",
       " ' Spadikam',\n",
       " ' Drishyam',\n",
       " ' Agent Sai Srinivasa Athreya',\n",
       " ' Vikram Vedha',\n",
       " ' Super Deluxe',\n",
       " ' Aruvi',\n",
       " ' Tumbbad',\n",
       " ' Mahanati',\n",
       " ' Khosla Ka Ghosla!',\n",
       " ' Anand',\n",
       " ' Pudhu Pettai',\n",
       " ' Premam',\n",
       " ' Kaakkaa Muttai',\n",
       " ' Anniyan',\n",
       " ' Andhadhun',\n",
       " ' Mudhalvan',\n",
       " ' Bangalore Days',\n",
       " ' Dhuruvangal Pathinaaru',\n",
       " ' Satya',\n",
       " ' Papanasam',\n",
       " ' Shahid',\n",
       " ' Soodhu Kavvum',\n",
       " ' Pithamagan',\n",
       " ' Jigarthanda',\n",
       " ' Gangs of Wasseypur',\n",
       " ' Sairat',\n",
       " ' Paan Singh Tomar',\n",
       " ' Bhaag Milkha Bhaag',\n",
       " ' Talvar',\n",
       " ' Hera Pheri',\n",
       " ' Swades: We, the People',\n",
       " ' Sholay',\n",
       " ' Black',\n",
       " ' Ustad Hotel',\n",
       " ' Chak De! India',\n",
       " ' Nil Battey Sannata',\n",
       " ' Jo Jeeta Wohi Sikandar',\n",
       " ' Charulata',\n",
       " ' Drishyam',\n",
       " ' Mughal-E-Azam',\n",
       " ' Maheshinte Prathikaaram',\n",
       " ' Zindagi Na Milegi Dobara',\n",
       " ' Article 15',\n",
       " ' Udaan',\n",
       " ' A Wednesday',\n",
       " ' Theeran adhigaaram ondru',\n",
       " ' Queen',\n",
       " ' Masaan',\n",
       " ' Sarfarosh',\n",
       " ' Munna Bhai M.B.B.S.',\n",
       " ' Alai Payuthey',\n",
       " ' Roja',\n",
       " ' Dil Chahta Hai',\n",
       " ' Baasha',\n",
       " ' OMG: Oh My God!',\n",
       " ' Rang De Basanti',\n",
       " ' Lagaan: Once Upon a Time in India',\n",
       " ' Kahaani',\n",
       " ' Andaz Apna Apna',\n",
       " ' Chhichhore',\n",
       " ' Uri: The Surgical Strike',\n",
       " ' Virumandi',\n",
       " ' PK',\n",
       " '  Lucia']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list = []\n",
    "for i in name:\n",
    "    name_list.append(i.text.replace('\\n','').strip())\n",
    "\n",
    "nl1 = name_list[:100]\n",
    "\n",
    "nl2 =[]\n",
    "for i in nl1:\n",
    "    nl2.append(i.replace(i[-6:],''))\n",
    "nl2\n",
    "nl3 = []\n",
    "for i in nl2:\n",
    "    nl3.append(i.replace(i[0:8],''))\n",
    "nl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_list = []\n",
    "for i in nl1:\n",
    "    year_list.append(i[-5:-1])\n",
    "    \n",
    "yl=year_list\n",
    "len(yl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rating = soup.find_all('td', class_ = \"ratingColumn imdbRating\")\n",
    "# rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_list = []\n",
    "for i in rating:\n",
    "    rating_list.append(i.text.replace('\\n',''))\n",
    "    \n",
    "rl = rating_list [ :100]\n",
    "len(rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Chhichhore</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Virumandi</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PK</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lucia</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name IMDB Rating Year of Release\n",
       "0             Pather Panchali         8.5            1955\n",
       "1                     Nayakan         8.5            1987\n",
       "2                  Anbe Sivam         8.5            2003\n",
       "3           Pariyerum Perumal         8.5            2018\n",
       "4                     Golmaal         8.5            1979\n",
       "..                        ...         ...             ...\n",
       "95                 Chhichhore         8.1            2019\n",
       "96   Uri: The Surgical Strike         8.1            2018\n",
       "97                  Virumandi         8.1            2004\n",
       "98                         PK         8.1            2014\n",
       "99                      Lucia         8.1            2013\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "top_indian_movies = pd.DataFrame({})\n",
    "top_indian_movies['Name'] = nl3\n",
    "top_indian_movies['IMDB Rating'] = rl\n",
    "top_indian_movies['Year of Release'] = yl\n",
    "\n",
    "top_indian_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------QUESTION 4------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"https://bookpage.com/reviews\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['All Our Hidden Gifts',\n",
       " 'Americanon',\n",
       " 'The Chosen and the Beautiful',\n",
       " 'Rez Dogs',\n",
       " \"Somebody's Daughter\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_name = soup.find_all('h4', class_='italic')\n",
    "book_name_list=[]\n",
    "for i in book_name:\n",
    "    book_name_list.append(i.text.replace('★',''))\n",
    "bnl = []\n",
    "for i in book_name_list:\n",
    "    bnl.append(i.replace('\\n','').strip())\n",
    "bnl = bnl[:5]\n",
    "bnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Caroline O'Donoghue\",\n",
       " 'Jess McHugh',\n",
       " 'Nghi Vo',\n",
       " 'Joseph Bruchac',\n",
       " 'Ashley C. Ford']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_name = soup.find_all('p', class_ = 'sans bold')\n",
    "author_name_list = []\n",
    "for i in author_name:\n",
    "    author_name_list.append(i.text.replace('\\n',''))\n",
    "anl = author_name_list[:5]\n",
    "anl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YA / YA Fiction',\n",
       " 'Nonfiction / American History / Literature',\n",
       " 'Science Fiction & Fantasy / Historical Fantasy',\n",
       " \"Children's / Middle Grade\",\n",
       " 'Nonfiction / Memoir']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = soup.find_all('p', class_ = 'genre-links hidden-phone')\n",
    "genre_list = []\n",
    "for i in genre:\n",
    "    genre_list.append(i.text.replace('\\n',''))\n",
    "gl = genre_list[:5]\n",
    "gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p>When Maeve is tasked with cleaning out a storage space at school as a punishment for throwing her shoe at a teacher, she finds an old tarot deck.',\n",
       " 'Jess McHugh’s book is essential reading—illuminating, engaging and absorbing. You’ll never look at the dictionary or cookbook on your shelf the same way.',\n",
       " '',\n",
       " '',\n",
       " 'Somebody’s Daughter is part Midwestern Black girl bildungsroman and part family saga about the rippling effects of incarceration.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_review = soup.find_all('p', class_ = 'excerpt')\n",
    "book_review\n",
    "book_review_list = []\n",
    "for i in book_review:\n",
    "    book_review_list.append(i.text.replace('\\n',''))\n",
    "brl = book_review_list[:5]\n",
    "brl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Our Hidden Gifts</td>\n",
       "      <td>Caroline O'Donoghue</td>\n",
       "      <td>YA / YA Fiction</td>\n",
       "      <td>p&gt;When Maeve is tasked with cleaning out a sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Americanon</td>\n",
       "      <td>Jess McHugh</td>\n",
       "      <td>Nonfiction / American History / Literature</td>\n",
       "      <td>Jess McHugh’s book is essential reading—illumi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Chosen and the Beautiful</td>\n",
       "      <td>Nghi Vo</td>\n",
       "      <td>Science Fiction &amp; Fantasy / Historical Fantasy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rez Dogs</td>\n",
       "      <td>Joseph Bruchac</td>\n",
       "      <td>Children's / Middle Grade</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Somebody's Daughter</td>\n",
       "      <td>Ashley C. Ford</td>\n",
       "      <td>Nonfiction / Memoir</td>\n",
       "      <td>Somebody’s Daughter is part Midwestern Black g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Book Name          Author Name  \\\n",
       "0          All Our Hidden Gifts  Caroline O'Donoghue   \n",
       "1                    Americanon          Jess McHugh   \n",
       "2  The Chosen and the Beautiful              Nghi Vo   \n",
       "3                      Rez Dogs       Joseph Bruchac   \n",
       "4           Somebody's Daughter       Ashley C. Ford   \n",
       "\n",
       "                                            Genre  \\\n",
       "0                                 YA / YA Fiction   \n",
       "1      Nonfiction / American History / Literature   \n",
       "2  Science Fiction & Fantasy / Historical Fantasy   \n",
       "3                       Children's / Middle Grade   \n",
       "4                             Nonfiction / Memoir   \n",
       "\n",
       "                                              Review  \n",
       "0  p>When Maeve is tasked with cleaning out a sto...  \n",
       "1  Jess McHugh’s book is essential reading—illumi...  \n",
       "2                                                     \n",
       "3                                                     \n",
       "4  Somebody’s Daughter is part Midwestern Black g...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_info = pd.DataFrame({})\n",
    "book_info['Book Name'] = bnl\n",
    "book_info['Author Name'] = anl\n",
    "book_info['Genre'] = gl\n",
    "book_info['Review'] = brl\n",
    "\n",
    "book_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------- QUESTION 5-----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Zealand',\n",
       " 'Australia',\n",
       " 'India',\n",
       " 'England',\n",
       " 'South Africa',\n",
       " 'Pakistan',\n",
       " 'Bangladesh',\n",
       " 'West Indies',\n",
       " 'Sri Lanka',\n",
       " 'Afghanistan']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = soup.find_all('span', class_='u-hide-phablet')\n",
    "team_name =  []\n",
    "for i in team:\n",
    "    team_name.append(i.text.replace('\\n',''))\n",
    "team_name = team_name[:10]\n",
    "team_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = soup.find('td', class_= 'rankings-block__banner--matches')\n",
    "match = match.text.replace('\\n','')\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25', '29', '27', '20', '24', '27', '27', '24', '17']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = soup.find_all('td', class_ = \"table-body__cell u-center-text\")\n",
    "matches_list = []\n",
    "for i in matches:\n",
    "    matches_list.append(i.text.replace('\\n',''))\n",
    "matches_list = matches_list[:18:2]\n",
    "matches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2,054'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point = soup.find('td', class_= 'rankings-block__banner--points')\n",
    "point = point.text.replace('\\n','')\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,945',\n",
       " '3,344',\n",
       " '3,100',\n",
       " '2,137',\n",
       " '2,323',\n",
       " '2,438',\n",
       " '2,222',\n",
       " '1,876',\n",
       " '1,054']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = soup.find_all('td', class_ = \"table-body__cell u-center-text\")\n",
    "points_list = []\n",
    "for i in points:\n",
    "    points_list.append(i.text.replace('\\n',''))\n",
    "points_list = points_list[1:19:2]\n",
    "points_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17', '25', '29', '27', '20', '24', '27', '27', '24', '17']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_list.insert(0,match)\n",
    "matches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,054',\n",
       " '2,945',\n",
       " '3,344',\n",
       " '3,100',\n",
       " '2,137',\n",
       " '2,323',\n",
       " '2,438',\n",
       " '2,222',\n",
       " '1,876',\n",
       " '1,054']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_list.insert(0,point)\n",
    "points_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'121'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = soup.find('td', class_ = 'rankings-block__banner--rating u-text-right')\n",
    "rating = rating.text.replace('\\n','').strip()\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['118', '115', '115', '107', '97', '90', '82', '78', '62']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = soup.find_all('td', class_ = 'table-body__cell u-text-right rating')\n",
    "ratings_list = []\n",
    "for i in ratings:\n",
    "    ratings_list.append(i.text.replace('\\n',''))\n",
    "ratings_list = ratings_list[:9]\n",
    "ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_list.insert(0,rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['121', '118', '115', '115', '107', '97', '90', '82', '78', '62']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "l = [team_name,matches_list,points_list,ratings_list]\n",
    "for i in l:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ODI_mens_team = pd.DataFrame({})\n",
    "ODI_mens_team['Team'] = team_name\n",
    "ODI_mens_team['Matches'] = matches_list\n",
    "ODI_mens_team['Points'] = points_list\n",
    "ODI_mens_team['Ratings'] = ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>3,344</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,100</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>20</td>\n",
       "      <td>2,137</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>2,323</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>27</td>\n",
       "      <td>2,438</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>24</td>\n",
       "      <td>1,876</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points Ratings\n",
       "0   New Zealand      17  2,054     121\n",
       "1     Australia      25  2,945     118\n",
       "2         India      29  3,344     115\n",
       "3       England      27  3,100     115\n",
       "4  South Africa      20  2,137     107\n",
       "5      Pakistan      24  2,323      97\n",
       "6    Bangladesh      27  2,438      90\n",
       "7   West Indies      27  2,222      82\n",
       "8     Sri Lanka      24  1,876      78\n",
       "9   Afghanistan      17  1,054      62"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODI_mens_team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Babar Azam'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player = soup.find('div', class_ = \"rankings-block__banner--name-large\")\n",
    "player = player.text.replace('/n','')\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam',\n",
       " 'Virat Kohli',\n",
       " 'Rohit Sharma',\n",
       " 'Ross Taylor',\n",
       " 'Aaron Finch',\n",
       " 'Jonny Bairstow',\n",
       " 'Fakhar Zaman',\n",
       " 'Francois du Plessis',\n",
       " 'David Warner',\n",
       " 'Shai Hope']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = soup.find_all('td', class_ = 'table-body__cell rankings-table__name name')\n",
    "players_list = []\n",
    "for i in players:\n",
    "    players_list.append(i.text.replace('\\n',''))\n",
    "players_list = players_list[:9]\n",
    "players_list.insert(0,player)\n",
    "players_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PAK'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = soup.find('div', class_ = 'rankings-block__banner--nationality')\n",
    "team = team.text.replace('\\n','').strip()\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAK', 'IND', 'IND', 'NZ', 'AUS', 'ENG', 'PAK', 'SA', 'AUS', 'WI']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = soup.find_all('span', class_ = 'table-body__logo-text')\n",
    "teams_list = []\n",
    "for i in teams:\n",
    "    teams_list.append(i.text.replace('\\n',''))\n",
    "teams_list.insert(0,team)\n",
    "teams_list = teams_list[:10]\n",
    "teams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'865'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = soup.find('div', class_ = 'rankings-block__banner--rating')\n",
    "rating = rating.text\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['865', '857', '825', '801', '791', '785', '778', '778', '773', '773']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = soup.find_all('td', class_ = 'table-body__cell rating')\n",
    "ratings_list = []\n",
    "for i in ratings:\n",
    "    ratings_list.append(i.text)\n",
    "ratings_list.insert(0,rating)\n",
    "ratings_list = ratings_list[:10]\n",
    "ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player Team Rating\n",
       "0           Babar Azam  PAK    865\n",
       "1          Virat Kohli  IND    857\n",
       "2         Rohit Sharma  IND    825\n",
       "3          Ross Taylor   NZ    801\n",
       "4          Aaron Finch  AUS    791\n",
       "5       Jonny Bairstow  ENG    785\n",
       "6         Fakhar Zaman  PAK    778\n",
       "7  Francois du Plessis   SA    778\n",
       "8         David Warner  AUS    773\n",
       "9            Shai Hope   WI    773"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODI_mensbatting_ranking = pd.DataFrame({})\n",
    "ODI_mensbatting_ranking['Player'] = players_list\n",
    "ODI_mensbatting_ranking['Team'] = teams_list\n",
    "ODI_mensbatting_ranking['Rating'] = ratings_list\n",
    "ODI_mensbatting_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trent Boult'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ply = soup.find('div', class_ = 'rankings-block__banner--name-large')\n",
    "ply = ply.text\n",
    "ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trent Boult',\n",
       " 'Mehedi Hasan',\n",
       " 'Mujeeb Ur Rahman',\n",
       " 'Matt Henry',\n",
       " 'Jasprit Bumrah',\n",
       " 'Kagiso Rabada',\n",
       " 'Chris Woakes',\n",
       " 'Josh Hazlewood',\n",
       " 'Mustafizur Rahman',\n",
       " 'Pat Cummins']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plys = soup.find_all('td', class_ = 'table-body__cell rankings-table__name name')\n",
    "plys_l = []\n",
    "for i in plys:\n",
    "    plys_l.append(i.text.replace('\\n',''))\n",
    "plys_l.insert(0,ply)\n",
    "plys_l = plys_l[:10]\n",
    "plys_l\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NZ'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = soup.find('div', class_ = 'rankings-block__banner--nationality')\n",
    "team = team.text.replace('\\n','').strip()\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NZ', 'BAN', 'AFG', 'NZ', 'IND', 'SA', 'ENG', 'AUS', 'BAN', 'AUS']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = soup.find_all('span', class_ = 'table-body__logo-text')\n",
    "teams_list = []\n",
    "for i in teams:\n",
    "    teams_list.append(i.text.replace('\\n',''))\n",
    "teams_list.insert(0,team)\n",
    "teams_list = teams_list[:10]\n",
    "teams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'737'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = soup.find('div', class_ = 'rankings-block__banner--rating')\n",
    "rating = rating.text\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['737', '725', '708', '691', '690', '666', '665', '660', '652', '646']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = soup.find_all('td', class_ = 'table-body__cell rating')\n",
    "ratings_list = []\n",
    "for i in ratings:\n",
    "    ratings_list.append(i.text)\n",
    "ratings_list.insert(0,rating)\n",
    "ratings_list = ratings_list[:10]\n",
    "ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Rating\n",
       "0        Trent Boult   NZ    737\n",
       "1       Mehedi Hasan  BAN    725\n",
       "2   Mujeeb Ur Rahman  AFG    708\n",
       "3         Matt Henry   NZ    691\n",
       "4     Jasprit Bumrah  IND    690\n",
       "5      Kagiso Rabada   SA    666\n",
       "6       Chris Woakes  ENG    665\n",
       "7     Josh Hazlewood  AUS    660\n",
       "8  Mustafizur Rahman  BAN    652\n",
       "9        Pat Cummins  AUS    646"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODI_mensbowling_ranking = pd.DataFrame({})\n",
    "ODI_mensbowling_ranking['Player'] = plys_l\n",
    "ODI_mensbowling_ranking['Team'] = teams_list\n",
    "ODI_mensbowling_ranking['Rating'] = ratings_list\n",
    "ODI_mensbowling_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------- Question 6 -----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'South Africa',\n",
       " 'England',\n",
       " 'India',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Pakistan',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'Ireland']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = soup.find_all('span', class_='u-hide-phablet')\n",
    "team_name =  []\n",
    "for i in team:\n",
    "    team_name.append(i.text.replace('\\n',''))\n",
    "team_name = team_name[:10]\n",
    "team_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18', '24', '17', '20', '21', '12', '15', '5', '11', '2']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = soup.find('td', class_= 'rankings-block__banner--matches')\n",
    "match = match.text.replace('\\n','')\n",
    "matches = soup.find_all('td', class_ = \"table-body__cell u-center-text\")\n",
    "matches_list = []\n",
    "for i in matches:\n",
    "    matches_list.append(i.text.replace('\\n',''))\n",
    "matches_list = matches_list[:18:2]\n",
    "matches_list.insert(0,match)\n",
    "matches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,955',\n",
       " '2,828',\n",
       " '1,993',\n",
       " '2,226',\n",
       " '1,947',\n",
       " '1,025',\n",
       " '1,101',\n",
       " '306',\n",
       " '519',\n",
       " '25']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point = soup.find('td', class_= 'rankings-block__banner--points')\n",
    "point = point.text.replace('\\n','')\n",
    "points = soup.find_all('td', class_ = \"table-body__cell u-center-text\")\n",
    "points_list = []\n",
    "for i in points:\n",
    "    points_list.append(i.text.replace('\\n',''))\n",
    "points_list = points_list[1:19:2]\n",
    "points_list.insert(0,point)\n",
    "points_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['164', '118', '117', '111', '93', '85', '73', '61', '47', '13']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = soup.find('td', class_ = 'rankings-block__banner--rating u-text-right')\n",
    "rating = rating.text.replace('\\n','').strip()\n",
    "ratings = soup.find_all('td', class_ = 'table-body__cell u-text-right rating')\n",
    "ratings_list = []\n",
    "for i in ratings:\n",
    "    ratings_list.append(i.text.replace('\\n',''))\n",
    "ratings_list = ratings_list[:9]\n",
    "ratings_list.insert(0,rating)\n",
    "ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points Ratings\n",
       "0     Australia      18  2,955     164\n",
       "1  South Africa      24  2,828     118\n",
       "2       England      17  1,993     117\n",
       "3         India      20  2,226     111\n",
       "4   New Zealand      21  1,947      93\n",
       "5   West Indies      12  1,025      85\n",
       "6      Pakistan      15  1,101      73\n",
       "7    Bangladesh       5    306      61\n",
       "8     Sri Lanka      11    519      47\n",
       "9       Ireland       2     25      13"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODI_womens_team = pd.DataFrame({})\n",
    "ODI_womens_team['Team'] = team_name\n",
    "ODI_womens_team['Matches'] = matches_list\n",
    "ODI_womens_team['Points'] = points_list\n",
    "ODI_womens_team['Ratings'] = ratings_list\n",
    "ODI_womens_team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tammy Beaumont',\n",
       " 'Lizelle Lee',\n",
       " 'Alyssa Healy',\n",
       " 'Stafanie Taylor',\n",
       " 'Meg Lanning',\n",
       " 'Amy Satterthwaite',\n",
       " 'Smriti Mandhana',\n",
       " 'Mithali Raj',\n",
       " 'Natalie Sciver',\n",
       " 'Laura Wolvaardt']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player = soup.find('div', class_ = \"rankings-block__banner--name-large\")\n",
    "player = player.text.replace('/n','')\n",
    "players = soup.find_all('td', class_ = 'table-body__cell rankings-table__name name')\n",
    "players_list = []\n",
    "for i in players:\n",
    "    players_list.append(i.text.replace('\\n',''))\n",
    "players_list = players_list[:9]\n",
    "players_list.insert(0,player)\n",
    "players_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENG', 'SA', 'AUS', 'WI', 'AUS', 'NZ', 'IND', 'IND', 'ENG', 'SA']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = soup.find('div', class_ = 'rankings-block__banner--nationality')\n",
    "team = team.text.replace('\\n','').strip()\n",
    "teams = soup.find_all('span', class_ = 'table-body__logo-text')\n",
    "teams_list = []\n",
    "for i in teams:\n",
    "    teams_list.append(i.text.replace('\\n',''))\n",
    "teams_list.insert(0,team)\n",
    "teams_list = teams_list[:10]\n",
    "teams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['765', '758', '756', '746', '723', '715', '710', '709', '685', '683']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = soup.find('div', class_ = 'rankings-block__banner--rating')\n",
    "rating = rating.text\n",
    "ratings = soup.find_all('td', class_ = 'table-body__cell rating')\n",
    "ratings_list = []\n",
    "for i in ratings:\n",
    "    ratings_list.append(i.text)\n",
    "ratings_list.insert(0,rating)\n",
    "ratings_list = ratings_list[:10]\n",
    "ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Rating\n",
       "0     Tammy Beaumont  ENG    765\n",
       "1        Lizelle Lee   SA    758\n",
       "2       Alyssa Healy  AUS    756\n",
       "3    Stafanie Taylor   WI    746\n",
       "4        Meg Lanning  AUS    723\n",
       "5  Amy Satterthwaite   NZ    715\n",
       "6    Smriti Mandhana  IND    710\n",
       "7        Mithali Raj  IND    709\n",
       "8     Natalie Sciver  ENG    685\n",
       "9    Laura Wolvaardt   SA    683"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODI_womens_topplayer = pd.DataFrame({})\n",
    "ODI_womens_topplayer['Player'] = players_list\n",
    "ODI_womens_topplayer['Team'] = teams_list\n",
    "ODI_womens_topplayer['Rating'] = ratings_list\n",
    "ODI_womens_topplayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "soup = BeautifulSoup(page.content)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marizanne Kapp',\n",
       " 'Ellyse Perry',\n",
       " 'Stafanie Taylor',\n",
       " 'Natalie Sciver',\n",
       " 'Deepti Sharma',\n",
       " 'Jess Jonassen',\n",
       " 'Ashleigh Gardner',\n",
       " 'Dane van Niekerk',\n",
       " 'Sophie Devine',\n",
       " 'Amelia Kerr']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ply = soup.find('div', class_ = 'rankings-block__banner--name-large')\n",
    "ply = ply.text\n",
    "plys = soup.find_all('td', class_ = 'table-body__cell rankings-table__name name')\n",
    "plys_l = []\n",
    "for i in plys:\n",
    "    plys_l.append(i.text.replace('\\n',''))\n",
    "plys_l.insert(0,ply)\n",
    "plys_l = plys_l[:10]\n",
    "plys_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SA', 'AUS', 'WI', 'ENG', 'IND', 'AUS', 'AUS', 'SA', 'NZ', 'NZ']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = soup.find('div', class_ = 'rankings-block__banner--nationality')\n",
    "team = team.text.replace('\\n','').strip()\n",
    "teams = soup.find_all('span', class_ = 'table-body__logo-text')\n",
    "teams_list = []\n",
    "for i in teams:\n",
    "    teams_list.append(i.text.replace('\\n',''))\n",
    "teams_list.insert(0,team)\n",
    "teams_list = teams_list[:10]\n",
    "teams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['418', '418', '410', '349', '343', '307', '252', '243', '242', '236']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = soup.find('div', class_ = 'rankings-block__banner--rating')\n",
    "rating = rating.text\n",
    "ratings = soup.find_all('td', class_ = 'table-body__cell rating')\n",
    "ratings_list = []\n",
    "for i in ratings:\n",
    "    ratings_list.append(i.text)\n",
    "ratings_list.insert(0,rating)\n",
    "ratings_list = ratings_list[:10]\n",
    "ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Rating\n",
       "0    Marizanne Kapp   SA    418\n",
       "1      Ellyse Perry  AUS    418\n",
       "2   Stafanie Taylor   WI    410\n",
       "3    Natalie Sciver  ENG    349\n",
       "4     Deepti Sharma  IND    343\n",
       "5     Jess Jonassen  AUS    307\n",
       "6  Ashleigh Gardner  AUS    252\n",
       "7  Dane van Niekerk   SA    243\n",
       "8     Sophie Devine   NZ    242\n",
       "9       Amelia Kerr   NZ    236"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODI_womens_allrounder = pd.DataFrame({})\n",
    "ODI_womens_allrounder['Player'] = plys_l\n",
    "ODI_womens_allrounder['Team'] = teams_list\n",
    "ODI_womens_allrounder['Rating'] = ratings_list\n",
    "ODI_womens_allrounder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------- QUESTION- 7 -----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [503]>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.amazon.in/s?k=mobile+phones+under+20000&i=electronics&rh=n%3A1805560031%2Cp_36%3A-2000000&qid=1622478681&rnid=1318502031&ref=sr_nr_p_36_4')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd_name = soup.find_all('span', class_= \"a-size-medium a-color-base a-text-normal\")\n",
    "prd_name\n",
    "prd_l = []\n",
    "for i in prd_name:\n",
    "    prd_l.append(i.text.replace('\\n','').split('(')[0].strip())\n",
    "prd_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd_price = soup.find_all('span', class_ = \"a-price-whole\")\n",
    "price_l = []\n",
    "for i in prd_price:\n",
    "    price_l.append(i.text)\n",
    "price_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_url = soup.find_all('img', class_ = 's-image') \n",
    "img_url_l = []\n",
    "for i in img_url:\n",
    "    img_url_l.append(i['src'])\n",
    "img_url_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rtn = soup.find_all('span', class_ = 'a-icon-alt')\n",
    "avg_rtn_l = []\n",
    "for i in avg_rtn:\n",
    "    avg_rtn_l.append(i.text[:3])\n",
    "avg_rtn_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "l = [prd_l,price_l,img_url_l,avg_rtn_l]\n",
    "for i in l:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_l = prd_l[:23]\n",
    "price_l = price_l[:23]\n",
    "img_url_l = img_url_l[:23]\n",
    "avg_rtn_l = avg_rtn_l[:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "l = [prd_l,price_l,img_url_l,avg_rtn_l]\n",
    "for i in l:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Average Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Product Name, Price, Image URL, Average Rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mob_u20k = pd.DataFrame({})\n",
    "Mob_u20k['Product Name'] = prd_l\n",
    "Mob_u20k['Price'] = price_l\n",
    "Mob_u20k['Image URL'] = img_url_l\n",
    "Mob_u20k['Average Rating'] = avg_rtn_l\n",
    "Mob_u20k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------Question 8-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YLUeCKgzZPY')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Memorial Day',\n",
       " 'Tuesday',\n",
       " 'Wednesday',\n",
       " 'Thursday',\n",
       " 'Friday',\n",
       " 'Saturday',\n",
       " 'Sunday']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day = soup.find_all('div', class_ = 'col-sm-2 forecast-label')\n",
    "day_l = []\n",
    "for i in day:\n",
    "    day_l.append(i.text)\n",
    "day_l = day_l[::2]\n",
    "day_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunny',\n",
       " 'Sunny',\n",
       " 'Mostly sunny',\n",
       " 'Mostly sunny',\n",
       " 'Mostly sunny',\n",
       " 'Sunny',\n",
       " 'Sunny']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh_des = soup.find_all('div', class_ = 'col-sm-10 forecast-text')\n",
    "sh_des_l = []\n",
    "for i in sh_des:\n",
    "    sh_des_l.append(i.text.split(',')[0])\n",
    "sh_des_l = sh_des_l[::2]\n",
    "sh_des_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['69', '69', '65', '66', '66', '68', '68']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = soup.find_all('div', class_ = 'col-sm-10 forecast-text')\n",
    "temp_l = []\n",
    "for i in temp:\n",
    "    temp_l.append(i.text.split('.')[0].split(' ')[-1])\n",
    "temp_l = temp_l[::2]\n",
    "temp_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Breezy, with a west southwest wind 7 to 12 mph increasing to 19 to 24 mph',\n",
       " ' Breezy, with a west southwest wind 15 to 24 mph, with gusts as high as 32 mph',\n",
       " ' Breezy, with a west southwest wind 15 to 22 mph, with gusts as high as 29 mph',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = soup.find_all('div', class_ = 'col-sm-10 forecast-text')\n",
    "desc_l = []\n",
    "for i in desc:\n",
    "    desc_l.append(i.text.split('.')[1])\n",
    "desc_l = desc_l[::2]\n",
    "desc_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day (Period)</th>\n",
       "      <th>Short Description</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Memorial Day</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>69</td>\n",
       "      <td>Breezy, with a west southwest wind 7 to 12 mp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>69</td>\n",
       "      <td>Breezy, with a west southwest wind 15 to 24 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Mostly sunny</td>\n",
       "      <td>65</td>\n",
       "      <td>Breezy, with a west southwest wind 15 to 22 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Mostly sunny</td>\n",
       "      <td>66</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Mostly sunny</td>\n",
       "      <td>66</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>68</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>68</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day (Period) Short Description Temperature  \\\n",
       "0  Memorial Day             Sunny          69   \n",
       "1       Tuesday             Sunny          69   \n",
       "2     Wednesday      Mostly sunny          65   \n",
       "3      Thursday      Mostly sunny          66   \n",
       "4        Friday      Mostly sunny          66   \n",
       "5      Saturday             Sunny          68   \n",
       "6        Sunday             Sunny          68   \n",
       "\n",
       "                                         Description  \n",
       "0   Breezy, with a west southwest wind 7 to 12 mp...  \n",
       "1   Breezy, with a west southwest wind 15 to 24 m...  \n",
       "2   Breezy, with a west southwest wind 15 to 22 m...  \n",
       "3                                                     \n",
       "4                                                     \n",
       "5                                                     \n",
       "6                                                     "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SF_Forecast = pd.DataFrame({})\n",
    "SF_Forecast['Day (Period)'] = day_l\n",
    "SF_Forecast['Short Description'] = sh_des_l\n",
    "SF_Forecast['Temperature'] = temp_l\n",
    "SF_Forecast['Description'] = desc_l\n",
    "SF_Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------- Question 9 -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://internshala.com/fresher-jobs')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Admission Counselor (Sales) ',\n",
       " 'Sales And Business Development Analyst ',\n",
       " 'Growth Hacking Digital Marketer ',\n",
       " 'Junior Node.js Developer ',\n",
       " 'Junior Digital Marketing Executive ',\n",
       " 'iOS App Developer ',\n",
       " 'Food Journalist ',\n",
       " 'Junior Software Developer ',\n",
       " 'Full Stack Developer ',\n",
       " 'Business Analyst ',\n",
       " 'Associate Full Stack Developer ',\n",
       " 'Full Stack Engineer ',\n",
       " 'Product Marketer ',\n",
       " 'Business Development Executive ',\n",
       " 'Associate - Business Development ',\n",
       " 'Research Analyst (Economics) ',\n",
       " 'Machine Learning Engineer ',\n",
       " 'Business Analyst ',\n",
       " 'Business Development Executive (Inside Sales) ',\n",
       " 'Business Development Associate ',\n",
       " 'Full Stack Software Engineer ',\n",
       " 'Associate Front End Developer ',\n",
       " 'Social Media Marketing Manager ',\n",
       " 'Talent Acquisition Executive ',\n",
       " 'Full Stack Developer ',\n",
       " 'Backend Developer ',\n",
       " 'Full Stack Developer ',\n",
       " 'Junior Sales Associate ',\n",
       " 'Digital Marketing Specialist ',\n",
       " 'Android App Developer ',\n",
       " 'Associate Data Scientist ',\n",
       " 'Junior Software Developer ',\n",
       " 'Associate Software Developer ',\n",
       " 'Full Stack Developer ',\n",
       " 'Associate UI/UX Designer ',\n",
       " 'Web Development Trainee ',\n",
       " 'Business Development Executive ',\n",
       " 'Full Stack Flutter Developer ',\n",
       " 'Associate Software Developer ',\n",
       " 'Hardware Simulation Engineer ']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = soup.find_all('div', class_ = 'heading_4_5 profile')\n",
    "jtl = []\n",
    "for i in job_title:\n",
    "    jtl.append(i.text.replace('\\n',''))\n",
    "jtl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sky Education Group',\n",
       " \"Mo's F&B Group\",\n",
       " 'Sleep Love',\n",
       " 'Askadmissions.ai',\n",
       " 'Krivy',\n",
       " 'Ascentspark Software Private Limited',\n",
       " 'Truffle Nation',\n",
       " 'Habitate Technologies Private Limited',\n",
       " 'SoluLab',\n",
       " 'SoluLab',\n",
       " 'REPOZITORY TECHNOLOGIES PRIVATE LIMITED',\n",
       " 'Beehive Academy India',\n",
       " 'Bip',\n",
       " 'Tabeazy',\n",
       " 'Leverage Edu',\n",
       " 'DEX-DEFT Research And Consulting OPC Private Limited',\n",
       " 'AIMonk Labs Technology Limited',\n",
       " 'Kasper Consulting Private Limited',\n",
       " 'GREedge',\n",
       " 'PEPKIDZ LEARNING',\n",
       " 'Flair Labs',\n",
       " 'Little Big Things',\n",
       " 'Little Olive',\n",
       " 'CrewKarma',\n",
       " 'Codfirm',\n",
       " 'WebMOBI',\n",
       " 'TMBill Software',\n",
       " 'Kraftshala',\n",
       " 'Black Jack',\n",
       " 'Storlyy',\n",
       " 'Softsensor.ai',\n",
       " 'ZoryBoard Software Solutions',\n",
       " 'SNet Labs Private Limited',\n",
       " 'RavGins International Private Limited (Wobb.ai)',\n",
       " 'RavGins International Private Limited (Wobb.ai)',\n",
       " 'Softsensor.ai',\n",
       " 'Square Select Estates',\n",
       " 'HeartShirt',\n",
       " 'Labellerr By Tensor Matics Private Limited',\n",
       " 'Keysight Technologies']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_name = soup.find_all('div', class_ = 'heading_6 company_name')\n",
    "comp_name_l = []\n",
    "for i in comp_name:\n",
    "    comp_name_l.append(i.text.replace('\\n','').strip())\n",
    "comp_name_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 LPA',\n",
       " \"Apply By30 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 3.1 LPA',\n",
       " \"Apply By30 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 3.5 LPA',\n",
       " \"Apply By30 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 4 LPA',\n",
       " \"Apply By30 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 LPA',\n",
       " \"Apply By30 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3.6 - 7 LPA',\n",
       " \"Apply By30 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 4.5 LPA',\n",
       " \"Apply By30 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  5.2 - 7 LPA',\n",
       " \"Apply By30 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 5 LPA',\n",
       " \"Apply By28 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 4.2 LPA',\n",
       " \"Apply By28 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 3.6 LPA',\n",
       " \"Apply By30 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  4.2 - 8.2 LPA',\n",
       " \"Apply By28 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 6 LPA',\n",
       " \"Apply By27 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 LPA',\n",
       " \"Apply By27 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3.6 LPA',\n",
       " \"Apply By27 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 LPA',\n",
       " \"Apply By30 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  5 - 6.5 LPA',\n",
       " \"Apply By27 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3.25 - 4 LPA',\n",
       " \"Apply By26 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3.75 LPA',\n",
       " \"Apply By26 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 4 LPA',\n",
       " \"Apply By25 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 4 LPA',\n",
       " \"Apply By25 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 5 LPA',\n",
       " \"Apply By25 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 3.2 LPA',\n",
       " \"Apply By25 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 5 LPA',\n",
       " \"Apply By24 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  5 - 8 LPA',\n",
       " \"Apply By24 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 LPA',\n",
       " \"Apply By24 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 LPA',\n",
       " \"Apply By24 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  4 LPA',\n",
       " \"Apply By24 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 5 LPA',\n",
       " \"Apply By24 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 3.5 LPA',\n",
       " \"Apply By23 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  4 - 8 LPA',\n",
       " \"Apply By24 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 4 LPA',\n",
       " \"Apply By20 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 3.2 LPA',\n",
       " \"Apply By20 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3.3 - 4 LPA',\n",
       " \"Apply By20 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 4 LPA',\n",
       " \"Apply By20 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 5 LPA',\n",
       " \"Apply By20 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 5 LPA',\n",
       " \"Apply By19 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  3 - 3.5 LPA',\n",
       " \"Apply By19 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  7 - 10 LPA',\n",
       " \"Apply By23 Jun' 21\",\n",
       " 'Start date                            Starts\\xa0Immediately',\n",
       " 'CTC  4 - 7 LPA',\n",
       " \"Apply By19 Jun' 21\"]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctc = soup.find_all('div', class_ = 'other_detail_item')\n",
    "ctcl = []\n",
    "for i in ctc:\n",
    "    ctcl.append(i.text.replace('\\n','').strip())\n",
    "ctcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3 LPA',\n",
       " '3 - 3.1 LPA',\n",
       " '3 - 3.5 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3 LPA',\n",
       " '3.6 - 7 LPA',\n",
       " '3 - 4.5 LPA',\n",
       " '5.2 - 7 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 4.2 LPA',\n",
       " '3 - 3.6 LPA',\n",
       " '4.2 - 8.2 LPA',\n",
       " '3 - 6 LPA',\n",
       " '3 LPA',\n",
       " '3.6 LPA',\n",
       " '3 LPA',\n",
       " '5 - 6.5 LPA',\n",
       " '3.25 - 4 LPA',\n",
       " '3.75 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 3.2 LPA',\n",
       " '3 - 5 LPA',\n",
       " '5 - 8 LPA',\n",
       " '3 LPA',\n",
       " '3 LPA',\n",
       " '4 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 3.5 LPA',\n",
       " '4 - 8 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3 - 3.2 LPA',\n",
       " '3.3 - 4 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 3.5 LPA',\n",
       " '7 - 10 LPA',\n",
       " '4 - 7 LPA']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctcl2 = []\n",
    "for i in ctcl:\n",
    "    if i[0] == 'C':\n",
    "        ctcl2.append(i[5:])\n",
    "    else:\n",
    "        continue\n",
    "ctcl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"30 Jun' 21\",\n",
       " \"30 Jun' 21\",\n",
       " \"30 Jun' 21\",\n",
       " \"30 Jun' 21\",\n",
       " \"30 Jun' 21\",\n",
       " \"30 Jun' 21\",\n",
       " \"30 Jun' 21\",\n",
       " \"30 Jun' 21\",\n",
       " \"28 Jun' 21\",\n",
       " \"28 Jun' 21\",\n",
       " \"30 Jun' 21\",\n",
       " \"28 Jun' 21\",\n",
       " \"27 Jun' 21\",\n",
       " \"27 Jun' 21\",\n",
       " \"27 Jun' 21\",\n",
       " \"30 Jun' 21\",\n",
       " \"27 Jun' 21\",\n",
       " \"26 Jun' 21\",\n",
       " \"26 Jun' 21\",\n",
       " \"25 Jun' 21\",\n",
       " \"25 Jun' 21\",\n",
       " \"25 Jun' 21\",\n",
       " \"25 Jun' 21\",\n",
       " \"24 Jun' 21\",\n",
       " \"24 Jun' 21\",\n",
       " \"24 Jun' 21\",\n",
       " \"24 Jun' 21\",\n",
       " \"24 Jun' 21\",\n",
       " \"24 Jun' 21\",\n",
       " \"23 Jun' 21\",\n",
       " \"24 Jun' 21\",\n",
       " \"20 Jun' 21\",\n",
       " \"20 Jun' 21\",\n",
       " \"20 Jun' 21\",\n",
       " \"20 Jun' 21\",\n",
       " \"20 Jun' 21\",\n",
       " \"19 Jun' 21\",\n",
       " \"19 Jun' 21\",\n",
       " \"23 Jun' 21\",\n",
       " \"19 Jun' 21\"]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_date_l = []\n",
    "for i in ctcl:\n",
    "    if i[0] == 'A':\n",
    "        apply_date_l.append(i[8:])\n",
    "    else:\n",
    "        continue\n",
    "apply_date_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Comapny Name</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admission Counselor (Sales)</td>\n",
       "      <td>Sky Education Group</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sales And Business Development Analyst</td>\n",
       "      <td>Mo's F&amp;B Group</td>\n",
       "      <td>3 - 3.1 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Growth Hacking Digital Marketer</td>\n",
       "      <td>Sleep Love</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Node.js Developer</td>\n",
       "      <td>Askadmissions.ai</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Digital Marketing Executive</td>\n",
       "      <td>Krivy</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iOS App Developer</td>\n",
       "      <td>Ascentspark Software Private Limited</td>\n",
       "      <td>3.6 - 7 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Food Journalist</td>\n",
       "      <td>Truffle Nation</td>\n",
       "      <td>3 - 4.5 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Junior Software Developer</td>\n",
       "      <td>Habitate Technologies Private Limited</td>\n",
       "      <td>5.2 - 7 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>SoluLab</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>28 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>SoluLab</td>\n",
       "      <td>3 - 4.2 LPA</td>\n",
       "      <td>28 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Associate Full Stack Developer</td>\n",
       "      <td>REPOZITORY TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>Beehive Academy India</td>\n",
       "      <td>4.2 - 8.2 LPA</td>\n",
       "      <td>28 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Product Marketer</td>\n",
       "      <td>Bip</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>27 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Tabeazy</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>27 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Associate - Business Development</td>\n",
       "      <td>Leverage Edu</td>\n",
       "      <td>3.6 LPA</td>\n",
       "      <td>27 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Research Analyst (Economics)</td>\n",
       "      <td>DEX-DEFT Research And Consulting OPC Private L...</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>AIMonk Labs Technology Limited</td>\n",
       "      <td>5 - 6.5 LPA</td>\n",
       "      <td>27 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Kasper Consulting Private Limited</td>\n",
       "      <td>3.25 - 4 LPA</td>\n",
       "      <td>26 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Business Development Executive (Inside Sales)</td>\n",
       "      <td>GREedge</td>\n",
       "      <td>3.75 LPA</td>\n",
       "      <td>26 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>PEPKIDZ LEARNING</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>25 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Full Stack Software Engineer</td>\n",
       "      <td>Flair Labs</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>25 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Associate Front End Developer</td>\n",
       "      <td>Little Big Things</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>25 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Social Media Marketing Manager</td>\n",
       "      <td>Little Olive</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>25 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Talent Acquisition Executive</td>\n",
       "      <td>CrewKarma</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Codfirm</td>\n",
       "      <td>5 - 8 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Backend Developer</td>\n",
       "      <td>WebMOBI</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>TMBill Software</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Junior Sales Associate</td>\n",
       "      <td>Kraftshala</td>\n",
       "      <td>4 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Digital Marketing Specialist</td>\n",
       "      <td>Black Jack</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Android App Developer</td>\n",
       "      <td>Storlyy</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>23 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Softsensor.ai</td>\n",
       "      <td>4 - 8 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Junior Software Developer</td>\n",
       "      <td>ZoryBoard Software Solutions</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>SNet Labs Private Limited</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>RavGins International Private Limited (Wobb.ai)</td>\n",
       "      <td>3.3 - 4 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Associate UI/UX Designer</td>\n",
       "      <td>RavGins International Private Limited (Wobb.ai)</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Web Development Trainee</td>\n",
       "      <td>Softsensor.ai</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Square Select Estates</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>19 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Full Stack Flutter Developer</td>\n",
       "      <td>HeartShirt</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>19 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>Labellerr By Tensor Matics Private Limited</td>\n",
       "      <td>7 - 10 LPA</td>\n",
       "      <td>23 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hardware Simulation Engineer</td>\n",
       "      <td>Keysight Technologies</td>\n",
       "      <td>4 - 7 LPA</td>\n",
       "      <td>19 Jun' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job Title  \\\n",
       "0                     Admission Counselor (Sales)    \n",
       "1          Sales And Business Development Analyst    \n",
       "2                 Growth Hacking Digital Marketer    \n",
       "3                        Junior Node.js Developer    \n",
       "4              Junior Digital Marketing Executive    \n",
       "5                               iOS App Developer    \n",
       "6                                 Food Journalist    \n",
       "7                       Junior Software Developer    \n",
       "8                            Full Stack Developer    \n",
       "9                                Business Analyst    \n",
       "10                 Associate Full Stack Developer    \n",
       "11                            Full Stack Engineer    \n",
       "12                               Product Marketer    \n",
       "13                 Business Development Executive    \n",
       "14               Associate - Business Development    \n",
       "15                   Research Analyst (Economics)    \n",
       "16                      Machine Learning Engineer    \n",
       "17                               Business Analyst    \n",
       "18  Business Development Executive (Inside Sales)    \n",
       "19                 Business Development Associate    \n",
       "20                   Full Stack Software Engineer    \n",
       "21                  Associate Front End Developer    \n",
       "22                 Social Media Marketing Manager    \n",
       "23                   Talent Acquisition Executive    \n",
       "24                           Full Stack Developer    \n",
       "25                              Backend Developer    \n",
       "26                           Full Stack Developer    \n",
       "27                         Junior Sales Associate    \n",
       "28                   Digital Marketing Specialist    \n",
       "29                          Android App Developer    \n",
       "30                       Associate Data Scientist    \n",
       "31                      Junior Software Developer    \n",
       "32                   Associate Software Developer    \n",
       "33                           Full Stack Developer    \n",
       "34                       Associate UI/UX Designer    \n",
       "35                        Web Development Trainee    \n",
       "36                 Business Development Executive    \n",
       "37                   Full Stack Flutter Developer    \n",
       "38                   Associate Software Developer    \n",
       "39                   Hardware Simulation Engineer    \n",
       "\n",
       "                                         Comapny Name            CTC  \\\n",
       "0                                 Sky Education Group          3 LPA   \n",
       "1                                      Mo's F&B Group    3 - 3.1 LPA   \n",
       "2                                          Sleep Love    3 - 3.5 LPA   \n",
       "3                                    Askadmissions.ai      3 - 4 LPA   \n",
       "4                                               Krivy          3 LPA   \n",
       "5                Ascentspark Software Private Limited    3.6 - 7 LPA   \n",
       "6                                      Truffle Nation    3 - 4.5 LPA   \n",
       "7               Habitate Technologies Private Limited    5.2 - 7 LPA   \n",
       "8                                             SoluLab      3 - 5 LPA   \n",
       "9                                             SoluLab    3 - 4.2 LPA   \n",
       "10            REPOZITORY TECHNOLOGIES PRIVATE LIMITED    3 - 3.6 LPA   \n",
       "11                              Beehive Academy India  4.2 - 8.2 LPA   \n",
       "12                                                Bip      3 - 6 LPA   \n",
       "13                                            Tabeazy          3 LPA   \n",
       "14                                       Leverage Edu        3.6 LPA   \n",
       "15  DEX-DEFT Research And Consulting OPC Private L...          3 LPA   \n",
       "16                     AIMonk Labs Technology Limited    5 - 6.5 LPA   \n",
       "17                  Kasper Consulting Private Limited   3.25 - 4 LPA   \n",
       "18                                            GREedge       3.75 LPA   \n",
       "19                                   PEPKIDZ LEARNING      3 - 4 LPA   \n",
       "20                                         Flair Labs      3 - 4 LPA   \n",
       "21                                  Little Big Things      3 - 5 LPA   \n",
       "22                                       Little Olive    3 - 3.2 LPA   \n",
       "23                                          CrewKarma      3 - 5 LPA   \n",
       "24                                            Codfirm      5 - 8 LPA   \n",
       "25                                            WebMOBI          3 LPA   \n",
       "26                                    TMBill Software          3 LPA   \n",
       "27                                         Kraftshala          4 LPA   \n",
       "28                                         Black Jack      3 - 5 LPA   \n",
       "29                                            Storlyy    3 - 3.5 LPA   \n",
       "30                                      Softsensor.ai      4 - 8 LPA   \n",
       "31                       ZoryBoard Software Solutions      3 - 4 LPA   \n",
       "32                          SNet Labs Private Limited    3 - 3.2 LPA   \n",
       "33    RavGins International Private Limited (Wobb.ai)    3.3 - 4 LPA   \n",
       "34    RavGins International Private Limited (Wobb.ai)      3 - 4 LPA   \n",
       "35                                      Softsensor.ai      3 - 5 LPA   \n",
       "36                              Square Select Estates      3 - 5 LPA   \n",
       "37                                         HeartShirt    3 - 3.5 LPA   \n",
       "38         Labellerr By Tensor Matics Private Limited     7 - 10 LPA   \n",
       "39                              Keysight Technologies      4 - 7 LPA   \n",
       "\n",
       "      Apply by  \n",
       "0   30 Jun' 21  \n",
       "1   30 Jun' 21  \n",
       "2   30 Jun' 21  \n",
       "3   30 Jun' 21  \n",
       "4   30 Jun' 21  \n",
       "5   30 Jun' 21  \n",
       "6   30 Jun' 21  \n",
       "7   30 Jun' 21  \n",
       "8   28 Jun' 21  \n",
       "9   28 Jun' 21  \n",
       "10  30 Jun' 21  \n",
       "11  28 Jun' 21  \n",
       "12  27 Jun' 21  \n",
       "13  27 Jun' 21  \n",
       "14  27 Jun' 21  \n",
       "15  30 Jun' 21  \n",
       "16  27 Jun' 21  \n",
       "17  26 Jun' 21  \n",
       "18  26 Jun' 21  \n",
       "19  25 Jun' 21  \n",
       "20  25 Jun' 21  \n",
       "21  25 Jun' 21  \n",
       "22  25 Jun' 21  \n",
       "23  24 Jun' 21  \n",
       "24  24 Jun' 21  \n",
       "25  24 Jun' 21  \n",
       "26  24 Jun' 21  \n",
       "27  24 Jun' 21  \n",
       "28  24 Jun' 21  \n",
       "29  23 Jun' 21  \n",
       "30  24 Jun' 21  \n",
       "31  20 Jun' 21  \n",
       "32  20 Jun' 21  \n",
       "33  20 Jun' 21  \n",
       "34  20 Jun' 21  \n",
       "35  20 Jun' 21  \n",
       "36  19 Jun' 21  \n",
       "37  19 Jun' 21  \n",
       "38  23 Jun' 21  \n",
       "39  19 Jun' 21  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresher_jobs = pd.DataFrame({})\n",
    "fresher_jobs['Job Title'] = jtl\n",
    "fresher_jobs['Comapny Name'] = comp_name_l\n",
    "fresher_jobs['CTC'] = ctcl2\n",
    "fresher_jobs['Apply by'] = apply_date_l\n",
    "fresher_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------- END---------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
